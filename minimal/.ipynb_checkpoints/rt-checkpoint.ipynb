{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100% [............................................................................] 116914 / 116914"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'E:\\\\Coronavirus\\\\Rt comm\\\\minimal\\\\states.json'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "from scipy.stats.distributions import gamma\n",
    "import json \n",
    "import wget\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "if os.path.exists(os.getcwd()+\"\\\\national.json\"):\n",
    "    os.remove(os.getcwd()+\"\\\\national.json\")\n",
    "wget.download('https://api.covid19india.org/data.json', os.getcwd()+\"\\\\national.json\")\n",
    "\n",
    "if os.path.exists(os.getcwd()+\"\\\\states.json\"):\n",
    "    os.remove(os.getcwd()+\"\\\\states.json\")\n",
    "wget.download('https://api.covid19india.org/states_daily.json', os.getcwd()+\"\\\\states.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pooled_SD(sds,means):\n",
    "    return np.sqrt((np.sum(sds**2,axis=0)+np.sum(means-np.mean(means,axis=0)))/sds.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation for Rt (India - No Import Adjustment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration:  2\r"
     ]
    }
   ],
   "source": [
    "dates = np.array([pd.to_datetime(i['date']+\"2020\") for i in json.load(open('national.json',))['cases_time_series']])\n",
    "confirmed = np.array([int(i['dailyconfirmed'])for i in json.load(open('national.json',))['cases_time_series']])\n",
    "\n",
    "confirmed = confirmed[dates>=pd.to_datetime(\"03/04/20\")]\n",
    "dates = dates[dates>=pd.to_datetime(\"03/04/20\")]\n",
    "\n",
    "real_data = confirmed\n",
    "\n",
    "rt = []\n",
    "dats = []\n",
    "for n in range(2):\n",
    "    print(\"Iteration: \",n+1,end='\\r')\n",
    "    dataset = np.copy(real_data)\n",
    "    G = gamma(3.325+0.616*np.random.normal(),0.979+0.195*np.random.normal())\n",
    "    for i in range(len(dataset)):\n",
    "        send_back = np.clip(np.round(G.rvs(np.max([0,int(dataset[i])]))),0,10)\n",
    "        send_back = send_back[i-send_back>=0]\n",
    "        dataset[i] = 0\n",
    "        for j in np.unique(np.int32(send_back)):\n",
    "            dataset[i-j] += np.sum(send_back==j)\n",
    "    dataset[::-1] = dataset[::-1]+np.random.negative_binomial(n=dataset[::-1]+1,p=G.cdf(np.arange(len(dataset))),size=len(dataset)) \n",
    "    df = pd.DataFrame()\n",
    "    df['active'] = dataset[:-3]\n",
    "    df['date'] = dates[:-3]\n",
    "    df.to_csv('dataset.csv',index=False)\n",
    "    call(['RScript.exe','scripts/Rt_analysis.R'])\n",
    "    rt.append(pd.read_csv('rtoutput.csv'))\n",
    "    dats.append(dataset[:-3])\n",
    "\n",
    "means = np.array([x[\"Mean(R)\"].values for x in rt])\n",
    "sds = np.array([x[\"Std(R)\"].values for x in rt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stindex = 2+5-1\n",
    "india = {\n",
    "        'dates':list(pd.Series(dates)[stindex:stindex+means.shape[1]].dt.strftime('%m-%d-%Y')),\n",
    "        'rt_point':list(means.mean(axis=0)),\n",
    "        'rt_sd':list(pooled_SD(sds,means)),\n",
    "        'rt_l95':list(means.mean(axis=0)-1.95996*pooled_SD(sds,means)),\n",
    "        'rt_u95':list(means.mean(axis=0)+1.95996*pooled_SD(sds,means)),\n",
    "        'rt_l50':list(means.mean(axis=0)-0.67449*pooled_SD(sds,means)),\n",
    "        'rt_u50':list(means.mean(axis=0)+0.67449*pooled_SD(sds,means)),\n",
    "        'cases_mean':list(np.mean(dats,axis=0)),\n",
    "        'cases_sd':list(np.std(dats,axis=0)),\n",
    "        'cases_dates':list(pd.Series(dates)[:-3].dt.strftime('%m-%d-%Y'))\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data['IN'] = india"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = list(filter(lambda v:len(v)<3,list(json.load(open('states.json',))['states_daily'][0].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = np.array([pd.to_datetime(i['date']) for i in filter(lambda v: v['status'] == 'Confirmed',json.load(open('states.json',))['states_daily'])])\n",
    "data = pd.DataFrame()\n",
    "for st in states:\n",
    "    data[st] = np.array([i[st] for i in filter(lambda v: v['status'] == 'Confirmed',json.load(open('states.json',))['states_daily'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace(r'^\\s*$', np.NaN, regex=True).fillna(0)\n",
    "data = data.astype(np.int32)\n",
    "data['date'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "state_id = {\"kl\":\"Kerala\",\n",
    "\"mh\":\"Maharashtra\",\n",
    "\"gj\":\"Gujarat\",\n",
    "\"dl\":\"Delhi\",\n",
    "\"rj\":\"Rajasthan\",\n",
    "\"tn\":\"Tamil Nadu\",\n",
    "\"mp\":\"Madhya Pradesh\",\n",
    "\"up\":\"Uttar Pradesh\",\n",
    "\"tg\":\"Telangana\",\n",
    "\"ap\":\"Andhra Pradesh\",\n",
    "\"ka\":\"Karnataka\",\n",
    "\"wb\":\"West Bengal\",\n",
    "\"jk\":\"Jammu and Kashmir\",\n",
    "\"hr\":\"Haryana\",\n",
    "\"pb\":\"Punjab\",\n",
    "\"br\":\"Bihar\",\n",
    "\"or\":\"Odisha\" }\n",
    "\n",
    "for state in state_id.keys():\n",
    "    print(\"\\n\",state)\n",
    "    boots = 100\n",
    "    real_data = data[state].values\n",
    "    df = pd.DataFrame()\n",
    "    df['active'] = real_data\n",
    "    df.to_csv('dataset.csv',index=False)\n",
    "    rt = []\n",
    "    dats = []\n",
    "    for n in range(boots):\n",
    "        print(\"Iteration: \",n+1,end='\\r')\n",
    "        G = gamma(3.325+0.616*np.random.normal(),0.979+0.195*np.random.normal())\n",
    "        dataset = np.copy(real_data)\n",
    "        for i in range(len(dataset)):\n",
    "            send_back = np.clip(np.round(G.rvs(np.max([0,int(dataset[i])]))),0,10)\n",
    "            send_back = send_back[i-send_back>=0]\n",
    "            dataset[i] = 0\n",
    "            for j in np.unique(np.int32(send_back)):\n",
    "                dataset[i-j] += np.sum(send_back==j)\n",
    "        dataset[::-1] = dataset[::-1]+np.random.negative_binomial(n=dataset[::-1]+1,p=G.cdf(np.arange(len(dataset))),size=len(dataset)) \n",
    "        df = pd.DataFrame()\n",
    "        df['active'] = dataset[:-3]\n",
    "        df['date'] = dates[:-3]\n",
    "        dats.append(dataset[:-3])\n",
    "        df.to_csv('dataset.csv',index=False)\n",
    "        call(['RScript.exe','scripts/Rt_analysis.R'])\n",
    "        rt.append(pd.read_csv('rtoutput.csv'))\n",
    "\n",
    "    means = np.array([x[\"Mean(R)\"].values for x in rt])\n",
    "    sds = np.array([x[\"Std(R)\"].values for x in rt])\n",
    "    dat_means = np.mean(dats,axis=0)\n",
    "    dat_sds = np.std(dats,axis=0)\n",
    "    \n",
    "    stindex = 2+5-1\n",
    "    temp = {\n",
    "            'dates':list(pd.Series(dates)[stindex:stindex+means.shape[1]].dt.strftime('%m-%d-%Y')),\n",
    "            'rt_point':list(means.mean(axis=0)),\n",
    "            'rt_sd':list(pooled_SD(sds,means)),\n",
    "            'rt_l95':list(means.mean(axis=0)-1.95996*pooled_SD(sds,means)),\n",
    "            'rt_u95':list(means.mean(axis=0)+1.95996*pooled_SD(sds,means)),\n",
    "            'rt_l50':list(means.mean(axis=0)-0.67449*pooled_SD(sds,means)),\n",
    "            'rt_u50':list(means.mean(axis=0)+0.67449*pooled_SD(sds,means)),\n",
    "            'cases_mean':list(np.mean(dats,axis=0)),\n",
    "            'cases_sd':list(np.std(dats,axis=0)),\n",
    "            'cases_dates':list(pd.Series(dates)[:-3].dt.strftime('%m-%d-%Y'))\n",
    "            }\n",
    "    json_data[state] = temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.json', 'w') as outfile:\n",
    "    json.dump(json_data, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
