{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 179
    },
    "colab_type": "code",
    "id": "BrAGPZahatRy",
    "outputId": "497acadd-dd9f-472d-c626-bef5b8f7d55d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wget\n",
      "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=e280bce5b0044e562091ffd6cfeca405de093bea7077e439495fab3144581f22\n",
      "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
      "Successfully built wget\n",
      "Installing collected packages: wget\n",
      "Successfully installed wget-3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "id": "YVYpa1FfWnWn",
    "outputId": "00d10d11-8332-4f81-dc98-e7b602eb2446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from subprocess import call\n",
    "from scipy.stats.distributions import gamma,lognorm\n",
    "import json \n",
    "import wget\n",
    "import os\n",
    "import os.path\n",
    "from google.colab import drive\n",
    "# os.chdir('/content/gdrive/My Drive')\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Jk2LDIwJAFWU",
    "outputId": "caee51e8-a36a-448d-c50f-c408d309f7d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/content//test.json'"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def n2z(x):\n",
    "    x[np.logical_or(np.isnan(x),np.isinf(x))] = 0\n",
    "    return x\n",
    "\n",
    "if os.path.exists(os.getcwd()+\"\\\\national.json\"):\n",
    "    os.remove(os.getcwd()+\"\\\\national.json\")\n",
    "wget.download('https://api.covid19india.org/data.json', os.getcwd()+\"//national.json\")\n",
    "\n",
    "if os.path.exists(os.getcwd()+\"\\\\states.json\"):\n",
    "    os.remove(os.getcwd()+\"\\\\states.json\")\n",
    "wget.download('https://api.covid19india.org/states_daily.json', os.getcwd()+\"//states.json\")\n",
    "\n",
    "if os.path.exists(os.getcwd()+\"\\\\test.json\"):\n",
    "    os.remove(os.getcwd()+\"\\\\test.json\")\n",
    "wget.download('https://api.covid19india.org/state_test_data.json', os.getcwd()+\"//test.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SPTNDutlus2X"
   },
   "outputs": [],
   "source": [
    "dataset=pd.read_csv('/content/gdrive/My Drive/population.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "mfv0_kipvTIo",
    "outputId": "b8e3652c-7aec-4706-f556-c131fcad899b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Population</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Delhi</td>\n",
       "      <td>18710922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Haryana</td>\n",
       "      <td>28204692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kerala</td>\n",
       "      <td>35699443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>7451955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Punjab</td>\n",
       "      <td>30141373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Telangana</td>\n",
       "      <td>39362732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Goa</td>\n",
       "      <td>1586250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>11250858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>1158473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gujarat</td>\n",
       "      <td>63872399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lakshadweep</td>\n",
       "      <td>73183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Dadra and Nagar Haveli and Daman and Diu</td>\n",
       "      <td>615724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>77841267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>29436231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Andaman and Nicobar Islands</td>\n",
       "      <td>417036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>123144223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Karnataka</td>\n",
       "      <td>67562686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>West Bengal</td>\n",
       "      <td>99609303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Odisha</td>\n",
       "      <td>46356334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Puducherry</td>\n",
       "      <td>1413542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>53903393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>38593948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Mizoram</td>\n",
       "      <td>1239244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Tripura</td>\n",
       "      <td>4169794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>85358965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>237882725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>81032689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sikkim</td>\n",
       "      <td>690251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bihar</td>\n",
       "      <td>124799926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Manipur</td>\n",
       "      <td>3091545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>1570458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Jammu and Kashmir</td>\n",
       "      <td>13606320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Ladakh</td>\n",
       "      <td>289023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Nagaland</td>\n",
       "      <td>2249695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>3366710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Assam</td>\n",
       "      <td>35607039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>India</td>\n",
       "      <td>1371360350</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       State  Population\n",
       "0                                      Delhi    18710922\n",
       "1                                    Haryana    28204692\n",
       "2                                     Kerala    35699443\n",
       "3                           Himachal Pradesh     7451955\n",
       "4                                     Punjab    30141373\n",
       "5                                  Telangana    39362732\n",
       "6                                        Goa     1586250\n",
       "7                                Uttarakhand    11250858\n",
       "8                                 Chandigarh     1158473\n",
       "9                                    Gujarat    63872399\n",
       "10                               Lakshadweep       73183\n",
       "11  Dadra and Nagar Haveli and Daman and Diu      615724\n",
       "12                                Tamil Nadu    77841267\n",
       "13                              Chhattisgarh    29436231\n",
       "14               Andaman and Nicobar Islands      417036\n",
       "15                               Maharashtra   123144223\n",
       "16                                 Karnataka    67562686\n",
       "17                               West Bengal    99609303\n",
       "18                                    Odisha    46356334\n",
       "19                                Puducherry     1413542\n",
       "20                            Andhra Pradesh    53903393\n",
       "21                                 Jharkhand    38593948\n",
       "22                                   Mizoram     1239244\n",
       "23                                   Tripura     4169794\n",
       "24                            Madhya Pradesh    85358965\n",
       "25                             Uttar Pradesh   237882725\n",
       "26                                 Rajasthan    81032689\n",
       "27                                    Sikkim      690251\n",
       "28                                     Bihar   124799926\n",
       "29                                   Manipur     3091545\n",
       "30                         Arunachal Pradesh     1570458\n",
       "31                         Jammu and Kashmir    13606320\n",
       "32                                    Ladakh      289023\n",
       "33                                  Nagaland     2249695\n",
       "34                                 Meghalaya     3366710\n",
       "35                                     Assam    35607039\n",
       "36                                     India  1371360350"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population=pd.DataFrame()\n",
    "population[\"State\"]=dataset['State'][:37]\n",
    "population[\"Population\"]=dataset['Population'][:37]\n",
    "population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6eMgJcoGcUrL"
   },
   "outputs": [],
   "source": [
    "def fn(mon):\n",
    "  if(mon == \"01\"):\n",
    "    return \" January\"\n",
    "  if(mon == \"02\"):\n",
    "    return \" February\"\n",
    "  if(mon == \"03\"):\n",
    "    return \" March\"\n",
    "  if(mon == \"04\"):\n",
    "    return \" April\"\n",
    "  if(mon == \"05\"):\n",
    "    return \" May\"\n",
    "  if(mon == \"06\"):\n",
    "    return \" June\"\n",
    "  if(mon == \"07\"):\n",
    "    return \" July\"\n",
    "  if(mon == \"08\"):\n",
    "    return \" August\"\n",
    "  if(mon == \"09\"):\n",
    "    return \" September\"\n",
    "  if(mon == \"10\"):\n",
    "    return \" October\"\n",
    "  if(mon == \"11\"):\n",
    "    return \" November\"\n",
    "  if(mon == \"12\"):\n",
    "    return \" December\"\n",
    "def convert(dat): \n",
    "    return  str(dat[:2]) + fn(str(dat[3:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vyJlOC14WnW3"
   },
   "outputs": [],
   "source": [
    "dates = np.array([pd.to_datetime(i['date']+\"2020\") for i in json.load(open('national.json',))['cases_time_series']])\n",
    "confirmed = np.array([int(i['dailyconfirmed'])for i in json.load(open('national.json',))['cases_time_series']])\n",
    "deceased = np.array([int(i['dailydeceased'])for i in json.load(open('national.json',))['cases_time_series']])\n",
    "recovered = np.array([int(i['dailyrecovered'])for i in json.load(open('national.json',))['cases_time_series']])\n",
    "\n",
    "confirmed = confirmed[dates>=pd.to_datetime(\"03/04/20\")]\n",
    "deceased = deceased[dates>=pd.to_datetime(\"03/04/20\")]\n",
    "recovered = recovered[dates>=pd.to_datetime(\"03/04/20\")]\n",
    "dates = dates[dates>=pd.to_datetime(\"03/04/20\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "colab_type": "code",
    "id": "xwporaXCWnXA",
    "outputId": "55e20c94-d8b5-4b97-8832-1742b4e44f0d",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "conf = []\n",
    "\n",
    "for n in range(100):\n",
    "    print(\"Iteration: \",n+1,end='\\r')\n",
    "    dataset = np.copy(confirmed)\n",
    "    mean = 13.0+(20.9-8.7)/4*np.random.normal()\n",
    "    sd = 12.7+(26.0-6.4)/4*np.random.normal()\n",
    "    phi = np.sqrt(sd**2 + mean**2)\n",
    "    mu = np.log(mean**2/phi)\n",
    "    sigma = np.sqrt(np.log(phi**2/mean**2))\n",
    "    L = lognorm(s=sigma,scale=np.exp(mu))\n",
    "    for i in range(len(dataset)-1,-1,-1):\n",
    "        send_forward = np.round(L.rvs(dataset[i]))\n",
    "        send_forward = send_forward[i+send_forward<len(dataset)]\n",
    "        dataset[i] = 0\n",
    "        for j in np.unique(np.int32(send_forward)):\n",
    "            dataset[i+j] += np.sum(send_forward==j)\n",
    "    conf.append(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "id": "xrhSandaWnXK",
    "outputId": "9f511958-58eb-47ee-ba4b-9bf4f59aceca"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "CFR = np.cumsum(deceased)/np.cumsum(conf,axis=1)\n",
    "col_mean = np.nanmean(CFR, axis=0)\n",
    "inds = np.where(np.isnan(CFR))\n",
    "CFR[inds] = np.take(col_mean, inds[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W6VbmLbTmC-N"
   },
   "outputs": [],
   "source": [
    "temp=dates\n",
    "dates=[]\n",
    "for i in range(len(temp)):\n",
    "  date=[]\n",
    "  t=(str(temp[i])).split()[0]\n",
    "  m=t[5:7]\n",
    "  d=t[-2:]\n",
    "  #print(m,t)\n",
    "  date.append(d)\n",
    "  date.append('/')\n",
    "  date.append(m)\n",
    "  date=''.join([str(elem) for elem in date])\n",
    "  #print(date)\n",
    "  dates.append(convert(date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "colab_type": "code",
    "id": "OIywF321WnXX",
    "outputId": "050b301f-21ad-4dc2-f464-fcf3de74e2f0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>dates</th>\n",
       "      <th>cfr1_point</th>\n",
       "      <th>cfr2_point</th>\n",
       "      <th>cfr3_point</th>\n",
       "      <th>cfr3_l95</th>\n",
       "      <th>cfr3_u95</th>\n",
       "      <th>cfr3_l50</th>\n",
       "      <th>cfr3_u50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>India</td>\n",
       "      <td>04 March</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>05 March</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>India</td>\n",
       "      <td>06 March</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>07 March</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>08 March</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>India</td>\n",
       "      <td>05 June</td>\n",
       "      <td>0.028147</td>\n",
       "      <td>0.055461</td>\n",
       "      <td>0.047024</td>\n",
       "      <td>0.037155</td>\n",
       "      <td>0.061513</td>\n",
       "      <td>0.041802</td>\n",
       "      <td>0.052139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>India</td>\n",
       "      <td>06 June</td>\n",
       "      <td>0.028163</td>\n",
       "      <td>0.055295</td>\n",
       "      <td>0.046862</td>\n",
       "      <td>0.037146</td>\n",
       "      <td>0.061111</td>\n",
       "      <td>0.041718</td>\n",
       "      <td>0.051936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>India</td>\n",
       "      <td>07 June</td>\n",
       "      <td>0.027987</td>\n",
       "      <td>0.054986</td>\n",
       "      <td>0.046409</td>\n",
       "      <td>0.036861</td>\n",
       "      <td>0.060434</td>\n",
       "      <td>0.041365</td>\n",
       "      <td>0.051427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>India</td>\n",
       "      <td>08 June</td>\n",
       "      <td>0.028107</td>\n",
       "      <td>0.054779</td>\n",
       "      <td>0.045988</td>\n",
       "      <td>0.036624</td>\n",
       "      <td>0.059685</td>\n",
       "      <td>0.041059</td>\n",
       "      <td>0.050916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>India</td>\n",
       "      <td>09 June</td>\n",
       "      <td>0.028077</td>\n",
       "      <td>0.054418</td>\n",
       "      <td>0.045565</td>\n",
       "      <td>0.036432</td>\n",
       "      <td>0.058951</td>\n",
       "      <td>0.040748</td>\n",
       "      <td>0.050357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    state     dates  cfr1_point  ...  cfr3_u95  cfr3_l50  cfr3_u50\n",
       "0   India  04 March    0.000000  ...  0.000000  0.000000  0.000000\n",
       "1   India  05 March    0.000000  ...  0.000000  0.000000  0.000000\n",
       "2   India  06 March    0.000000  ...  0.000000  0.000000  0.000000\n",
       "3   India  07 March    0.000000  ...  0.000000  0.000000  0.000000\n",
       "4   India  08 March    0.000000  ...  0.000000  0.000000  0.000000\n",
       "..    ...       ...         ...  ...       ...       ...       ...\n",
       "93  India   05 June    0.028147  ...  0.061513  0.041802  0.052139\n",
       "94  India   06 June    0.028163  ...  0.061111  0.041718  0.051936\n",
       "95  India   07 June    0.027987  ...  0.060434  0.041365  0.051427\n",
       "96  India   08 June    0.028107  ...  0.059685  0.041059  0.050916\n",
       "97  India   09 June    0.028077  ...  0.058951  0.040748  0.050357\n",
       "\n",
       "[98 rows x 9 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data = {}\n",
    "india = {\n",
    "        'dates':dates,\n",
    "        'cfr1_point':list(n2z(np.cumsum(deceased)/np.cumsum(confirmed))),\n",
    "        'cfr2_point':list(n2z(np.cumsum(deceased)/(np.cumsum(deceased)+np.cumsum(recovered)))),\n",
    "        'cfr3_point':list(n2z(np.mean(CFR,axis=0))),\n",
    "        'cfr3_l95':list(n2z(np.quantile(CFR,0.025,axis=0))),\n",
    "        'cfr3_u95':list(n2z(np.quantile(CFR,0.975,axis=0))),\n",
    "        'cfr3_l50':list(n2z(np.quantile(CFR,0.25,axis=0))),\n",
    "        'cfr3_u50':list(n2z(np.quantile(CFR,0.75,axis=0))),\n",
    "        }\n",
    "json_data['India'] = india\n",
    "cfr = pd.DataFrame()\n",
    "cfr['state']=['India']*len(dates)\n",
    "cfr['dates']=dates\n",
    "cfr['cfr1_point']=list(n2z(np.cumsum(deceased)/np.cumsum(confirmed)))\n",
    "cfr['cfr2_point']=list(n2z(np.cumsum(deceased)/(np.cumsum(deceased)+np.cumsum(recovered))))\n",
    "cfr['cfr3_point']=list(n2z(np.mean(CFR,axis=0)))\n",
    "cfr['cfr3_l95']=list(n2z(np.quantile(CFR,0.025,axis=0)))\n",
    "cfr['cfr3_u95']=list(n2z(np.quantile(CFR,0.975,axis=0)))\n",
    "cfr['cfr3_l50']=list(n2z(np.quantile(CFR,0.25,axis=0)))\n",
    "cfr['cfr3_u50']=list(n2z(np.quantile(CFR,0.75,axis=0)))\n",
    "cfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-TNPEM04As9f"
   },
   "outputs": [],
   "source": [
    "states = list(filter(lambda v:len(v)<3,list(json.load(open('states.json',))['states_daily'][0].keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "T377QO_CWnXk"
   },
   "outputs": [],
   "source": [
    "dates = np.array([pd.to_datetime(i['date']) for i in filter(lambda v: v['status'] == 'Confirmed',json.load(open('states.json',))['states_daily'])])\n",
    "#print(dates)\n",
    "data_recovered = pd.DataFrame()\n",
    "data_deceased = pd.DataFrame()\n",
    "data_confirmed = pd.DataFrame()\n",
    "for st in states:\n",
    "    data_confirmed[st] = np.array([i[st] for i in filter(lambda v: v['status'] == 'Confirmed',json.load(open('states.json',))['states_daily'])])\n",
    "    data_deceased[st] = np.array([i[st] for i in filter(lambda v: v['status'] == 'Deceased',json.load(open('states.json',))['states_daily'])])\n",
    "    data_recovered[st] = np.array([i[st] for i in filter(lambda v: v['status'] == 'Recovered',json.load(open('states.json',))['states_daily'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-fkTZLEnBiLi"
   },
   "outputs": [],
   "source": [
    "data_recovered = data_recovered.replace(r'^\\s*$', np.NaN, regex=True).fillna(0)\n",
    "data_recovered = data_recovered.astype(np.int32)\n",
    "data_confirmed = data_confirmed.replace(r'^\\s*$', np.NaN, regex=True).fillna(0)\n",
    "data_confirmed = data_confirmed.astype(np.int32)\n",
    "data_deceased = data_deceased.replace(r'^\\s*$', np.NaN, regex=True).fillna(0)\n",
    "data_deceased = data_deceased.astype(np.int32)\n",
    "data_deceased['date'] = dates\n",
    "data_recovered['date'] = dates\n",
    "data_confirmed['date'] = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 161
    },
    "colab_type": "code",
    "id": "0e8kFz1zWnXv",
    "outputId": "8737fd0a-2199-4a3a-9447-be25da6453f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: RuntimeWarning: divide by zero encountered in true_divide\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:57: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:84: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: RuntimeWarning: Mean of empty slice\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:69: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:83: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1080x504 with 0 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "final=pd.DataFrame\n",
    "plt.figure(1, figsize=(15, 7))\n",
    "state_id = {\n",
    "  \"kl\":\"Kerala\",\n",
    "  \"mh\":\"Maharashtra\",\n",
    "  \"gj\":\"Gujarat\",\n",
    "  \"dl\":\"Delhi\",\n",
    "  \"rj\":\"Rajasthan\",\n",
    "  \"tn\":\"Tamil Nadu\",\n",
    "  \"mp\":\"Madhya Pradesh\",\n",
    "  \"up\":\"Uttar Pradesh\",\n",
    "  \"tg\":\"Telangana\",\n",
    "  \"ap\":\"Andhra Pradesh\",\n",
    "  \"ka\":\"Karnataka\",\n",
    "  \"wb\":\"West Bengal\",\n",
    "  \"jk\":\"Jammu and Kashmir\",\n",
    "  \"hr\":\"Haryana\",\n",
    "  \"pb\":\"Punjab\",\n",
    "  \"br\":\"Bihar\",\n",
    "  \"or\":\"Odisha\",\n",
    "  \"jh\":\"Jharkand\",\n",
    "  \"ut\":\"Uttarakhand\",\n",
    "  \"hp\":\"Himachal Pradesh\",\n",
    "  \"ct\":\"Chhattisgarh\",\n",
    "  \"as\":\"Assam\",\n",
    "  \"ch\":\"Chandigarh\",\n",
    "  \"la\":\"Ladakh\",\n",
    "  \"an\":\"Andaman and Nicobar Islands\",\n",
    "  \"ml\":\"Meghalaya\",\n",
    "  \"ga\":\"Goa\",\n",
    "  \"py\":\"Puducherry\",\n",
    "  \"mn\":\"Manipur\",\n",
    "  \"tr\":\"Tripura\",\n",
    "  \"ar\":\"Arunachal Pradesh\",\n",
    "  \"mz\":\"Mizoram\" ,\n",
    "}\n",
    "\n",
    "for state in state_id.keys():\n",
    "    boots = 100\n",
    "    conf = []\n",
    "    for n in range(boots):\n",
    "        #print(\"Iteration: \",n+1,end='\\r')\n",
    "        dataset = np.copy(data_confirmed[state].values)\n",
    "        mean = 13.0+(20.9-8.7)/4*np.random.normal()\n",
    "        sd = 12.7+(26.0-6.4)/4*np.random.normal()\n",
    "        phi = np.sqrt(sd**2 + mean**2)\n",
    "        mu = np.log(mean**2/phi)\n",
    "        sigma = np.sqrt(np.log(phi**2/mean**2))\n",
    "        L = lognorm(s=sigma,scale=np.exp(mu))\n",
    "        for i in range(len(dataset)-1,-1,-1):\n",
    "            send_forward = np.round(L.rvs(np.max([dataset[i],0])))\n",
    "            send_forward = send_forward[i+send_forward<len(dataset)]\n",
    "            dataset[i] = 0\n",
    "            for j in np.unique(np.int32(send_forward)):\n",
    "                dataset[i+j] += np.sum(send_forward==j)\n",
    "        conf.append(dataset)\n",
    "    CFR = np.cumsum(data_deceased[state].values)/np.cumsum(conf,axis=1)\n",
    "    col_mean = np.nanmean(CFR, axis=0)\n",
    "    inds = np.where(np.isnan(CFR))\n",
    "    CFR[inds] = np.take(col_mean, inds[1])\n",
    "    temp1=list(pd.Series(dates).dt.strftime('%m-%d-%Y'))\n",
    "    #print(temp1[0])\n",
    "    dates1=[]\n",
    "    for i in range(len(temp1)):\n",
    "      date=temp1[i][3:5]+'/'+temp1[i][0:2]\n",
    "      dates1.append(convert(date))\n",
    "    temp = {\n",
    "        'dates':dates1,\n",
    "        'cfr1_point':list(n2z(np.cumsum(data_deceased[state].values)/np.cumsum(data_confirmed[state].values))),\n",
    "        'cfr2_point':list(n2z(np.cumsum(data_deceased[state].values)/(np.cumsum(data_deceased[state].values)+np.cumsum(data_recovered[state].values)))),\n",
    "        'cfr3_point':list(n2z(np.mean(CFR,axis=0))),\n",
    "        'cfr3_l95':list(n2z(np.quantile(CFR,0.025,axis=0))),\n",
    "        'cfr3_u95':list(n2z(np.quantile(CFR,0.975,axis=0))),\n",
    "        'cfr3_l50':list(n2z(np.quantile(CFR,0.25,axis=0))),\n",
    "        'cfr3_u50':list(n2z(np.quantile(CFR,0.75,axis=0))),\n",
    "        }\n",
    "    a=state_id[state]\n",
    "    #print(a)\n",
    "    json_data[str(a)] = temp\n",
    "    cfr_state=pd.DataFrame()\n",
    "    cfr_state['state']=[str(a)]*len(dates)\n",
    "    cfr_state['dates']=dates1\n",
    "    cfr_state['cfr1_point']=(list(n2z(np.cumsum(data_deceased[state].values)/np.cumsum(data_confirmed[state].values))))\n",
    "    cfr_state['cfr2_point']=(list(n2z(np.cumsum(data_deceased[state].values)/(np.cumsum(data_deceased[state].values)+np.cumsum(data_recovered[state].values)))))\n",
    "    cfr_state['cfr3_point']=(list(n2z(np.mean(CFR,axis=0))))\n",
    "    cfr_state['cfr3_l95']=(list(n2z(np.quantile(CFR,0.025,axis=0))))\n",
    "    cfr_state['cfr3_u95']=(list(n2z(np.quantile(CFR,0.975,axis=0))))\n",
    "    cfr_state['cfr3_l50']=(list(n2z(np.quantile(CFR,0.25,axis=0))))\n",
    "    cfr_state['cfr3_u50']=(list(n2z(np.quantile(CFR,0.75,axis=0))))\n",
    "    cfr=pd.concat([cfr, cfr_state])\n",
    "      \n",
    "    #plt.plot(temp['cfr3_point'],label=state)\n",
    "#plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ye-E6-FL9MFs"
   },
   "outputs": [],
   "source": [
    "cfr.to_csv('cfr.csv',index=False)\n",
    "from datetime import datetime\n",
    "json_data['datetime']=str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JG4bxq2JWnX7"
   },
   "outputs": [],
   "source": [
    "with open('cfr.json', 'w') as outfile:\n",
    "    json.dump(json_data, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2JUFGrCP6krl"
   },
   "outputs": [],
   "source": [
    "total_confirmed = [x['totalconfirmed'].split(' ')[0] for x in json.load(open('national.json',))['cases_time_series']] ## x_cumulative= 'totalconfirmed'\n",
    "daily_confirmed = [x['dailyconfirmed'].split(' ')[0] for x in json.load(open('national.json',))['cases_time_series']] ## x1\n",
    "daily_confirmed_ma=['']*7\n",
    "dates=[]\n",
    "daily_confirmed=list(map(int,daily_confirmed))\n",
    "for i in range(7,len(daily_confirmed)):\n",
    "  daily_confirmed_ma.append(sum(daily_confirmed[i-7:i])/7)\n",
    "datesspace = [x['date'] for x in json.load(open('national.json',))['cases_time_series']]\n",
    "for i in range(len(datesspace)):\n",
    "  dates.append(datesspace[i][0:-1])\n",
    "#print(total_confirmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "bb8gVynOgDE1",
    "outputId": "98ded9c7-28a2-4515-eff5-eb092e363146"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['30 January ',\n",
       " '31 January ',\n",
       " '01 February ',\n",
       " '02 February ',\n",
       " '03 February ',\n",
       " '04 February ',\n",
       " '05 February ',\n",
       " '06 February ',\n",
       " '07 February ',\n",
       " '08 February ',\n",
       " '09 February ',\n",
       " '10 February ',\n",
       " '11 February ',\n",
       " '12 February ',\n",
       " '13 February ',\n",
       " '14 February ',\n",
       " '15 February ',\n",
       " '16 February ',\n",
       " '17 February ',\n",
       " '18 February ',\n",
       " '19 February ',\n",
       " '20 February ',\n",
       " '21 February ',\n",
       " '22 February ',\n",
       " '23 February ',\n",
       " '24 February ',\n",
       " '25 February ',\n",
       " '26 February ',\n",
       " '27 February ',\n",
       " '28 February ',\n",
       " '29 February ',\n",
       " '01 March ',\n",
       " '02 March ',\n",
       " '03 March ',\n",
       " '04 March ',\n",
       " '05 March ',\n",
       " '06 March ',\n",
       " '07 March ',\n",
       " '08 March ',\n",
       " '09 March ',\n",
       " '10 March ',\n",
       " '11 March ',\n",
       " '12 March ',\n",
       " '13 March ',\n",
       " '14 March ',\n",
       " '15 March ',\n",
       " '16 March ',\n",
       " '17 March ',\n",
       " '18 March ',\n",
       " '19 March ',\n",
       " '20 March ',\n",
       " '21 March ',\n",
       " '22 March ',\n",
       " '23 March ',\n",
       " '24 March ',\n",
       " '25 March ',\n",
       " '26 March ',\n",
       " '27 March ',\n",
       " '28 March ',\n",
       " '29 March ',\n",
       " '30 March ',\n",
       " '31 March ',\n",
       " '01 April ',\n",
       " '02 April ',\n",
       " '03 April ',\n",
       " '04 April ',\n",
       " '05 April ',\n",
       " '06 April ',\n",
       " '07 April ',\n",
       " '08 April ',\n",
       " '09 April ',\n",
       " '10 April ',\n",
       " '11 April ',\n",
       " '12 April ',\n",
       " '13 April ',\n",
       " '14 April ',\n",
       " '15 April ',\n",
       " '16 April ',\n",
       " '17 April ',\n",
       " '18 April ',\n",
       " '19 April ',\n",
       " '20 April ',\n",
       " '21 April ',\n",
       " '22 April ',\n",
       " '23 April ',\n",
       " '24 April ',\n",
       " '25 April ',\n",
       " '26 April ',\n",
       " '27 April ',\n",
       " '28 April ',\n",
       " '29 April ',\n",
       " '30 April ',\n",
       " '01 May ',\n",
       " '02 May ',\n",
       " '03 May ',\n",
       " '04 May ',\n",
       " '05 May ',\n",
       " '06 May ',\n",
       " '07 May ',\n",
       " '08 May ',\n",
       " '09 May ',\n",
       " '10 May ',\n",
       " '11 May ',\n",
       " '12 May ',\n",
       " '13 May ',\n",
       " '14 May ',\n",
       " '15 May ',\n",
       " '16 May ',\n",
       " '17 May ',\n",
       " '18 May ',\n",
       " '19 May ',\n",
       " '20 May ',\n",
       " '21 May ',\n",
       " '22 May ',\n",
       " '23 May ',\n",
       " '24 May ',\n",
       " '25 May ',\n",
       " '26 May ',\n",
       " '27 May ',\n",
       " '28 May ',\n",
       " '29 May ',\n",
       " '30 May ',\n",
       " '31 May ',\n",
       " '01 June ',\n",
       " '02 June ',\n",
       " '03 June ',\n",
       " '04 June ',\n",
       " '05 June ',\n",
       " '06 June ',\n",
       " '07 June ',\n",
       " '08 June ',\n",
       " '09 June ']"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datesspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "F6ldldb_VMKW",
    "outputId": "bb039d37-8e5a-47f9-d389-a018ada3f85c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'30 January': 1, '31 January': 2, '01 February': 3, '02 February': 4, '03 February': 5, '04 February': 6, '05 February': 7, '06 February': 8, '07 February': 9, '08 February': 10, '09 February': 11, '10 February': 12, '11 February': 13, '12 February': 14, '13 February': 15, '14 February': 16, '15 February': 17, '16 February': 18, '17 February': 19, '18 February': 20, '19 February': 21, '20 February': 22, '21 February': 23, '22 February': 24, '23 February': 25, '24 February': 26, '25 February': 27, '26 February': 28, '27 February': 29, '28 February': 30, '29 February': 31, '01 March': 32, '02 March': 33, '03 March': 34, '04 March': 35, '05 March': 36, '06 March': 37, '07 March': 38, '08 March': 39, '09 March': 40, '10 March': 41, '11 March': 42, '12 March': 43, '13 March': 44, '14 March': 45, '15 March': 46, '16 March': 47, '17 March': 48, '18 March': 49, '19 March': 50, '20 March': 51, '21 March': 52, '22 March': 53, '23 March': 54, '24 March': 55, '25 March': 56, '26 March': 57, '27 March': 58, '28 March': 59, '29 March': 60, '30 March': 61, '31 March': 62, '01 April': 63, '02 April': 64, '03 April': 65, '04 April': 66, '05 April': 67, '06 April': 68, '07 April': 69, '08 April': 70, '09 April': 71, '10 April': 72, '11 April': 73, '12 April': 74, '13 April': 75, '14 April': 76, '15 April': 77, '16 April': 78, '17 April': 79, '18 April': 80, '19 April': 81, '20 April': 82, '21 April': 83, '22 April': 84, '23 April': 85, '24 April': 86, '25 April': 87, '26 April': 88, '27 April': 89, '28 April': 90, '29 April': 91, '30 April': 92, '01 May': 93, '02 May': 94, '03 May': 95, '04 May': 96, '05 May': 97, '06 May': 98, '07 May': 99, '08 May': 100, '09 May': 101, '10 May': 102, '11 May': 103, '12 May': 104, '13 May': 105, '14 May': 106, '15 May': 107, '16 May': 108, '17 May': 109, '18 May': 110, '19 May': 111, '20 May': 112, '21 May': 113, '22 May': 114, '23 May': 115, '24 May': 116, '25 May': 117, '26 May': 118, '27 May': 119, '28 May': 120, '29 May': 121, '30 May': 122, '31 May': 123, '01 June': 124, '02 June': 125, '03 June': 126, '04 June': 127, '05 June': 128, '06 June': 129, '07 June': 130, '08 June': 131, '09 June': 132}\n"
     ]
    }
   ],
   "source": [
    "dates_dict = {}\n",
    "count=1\n",
    "for i in dates:\n",
    "  if i not in dates_dict.keys():\n",
    "    dates_dict[i]=count\n",
    "    count+=1\n",
    "print(dates_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VpXtUkhyhGQ5"
   },
   "outputs": [],
   "source": [
    "def convert(dat): \n",
    "    return  str(dat[:2]) + fn(str(dat[3:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "jVOS4Hbh1v9G",
    "outputId": "863512c9-9e3e-42c7-ff76-ca73f4ba0cf7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1371360350"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "population['Population'][36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3SYxC6Y1hHRV"
   },
   "outputs": [],
   "source": [
    "datest=[x['updatetimestamp'].split(' ')[0] for x in json.load(open('national.json',))['tested']]\n",
    "#totalcumulative_tested = [] #y_cumulative\n",
    "y_cumulative1=[x['totalsamplestested'] for x in json.load(open('national.json',))['tested']]\n",
    "test_per_million=['']*len(dates)\n",
    "dates1=[]\n",
    "for i in (datest):\n",
    "  dates1.append(convert(i))\n",
    "datestest = []\n",
    "datestest.append(dates1[0])\n",
    "y_cumulative = []\n",
    "tested_cum=['']*len(dates)\n",
    "y_cumulative.append(y_cumulative1[0])\n",
    "### y = 'totalsamplestested'\n",
    "#daily_tested = [] # y1 (y_cumulative2-ycumulative1)\n",
    "for i in range(1,len(dates1)):\n",
    "  if (dates1[i]==dates1[i-1]):\n",
    "    y_cumulative[-1]=y_cumulative1[i]\n",
    "  else:\n",
    "    datestest.append(dates1[i])\n",
    "    y_cumulative.append(y_cumulative1[i])\n",
    "daily_tested=[]\n",
    "daily_tested_final=['']*len(dates)\n",
    "daily_confirmed_final=['']*len(dates)\n",
    "daily_confirmed_ma_final=['']*len(dates)\n",
    "daily_tested.append(y_cumulative[0])\n",
    "for i in range(1,len(y_cumulative)):\n",
    "  if (len(y_cumulative[i])!=0):\n",
    "    a=int(y_cumulative[i])-int(y_cumulative[i-1])\n",
    "    daily_tested.append(a)\n",
    "    #test_per_million.append(int(y_cumulative[i])*1000000/int(population['Population'][36]))\n",
    "  else:\n",
    "    y_cumulative[i]=y_cumulative[i-1]\n",
    "    daily_tested.append(0)\n",
    "    #test_per_million.append('')\n",
    "var=0\n",
    "pos_rate_cum=['']*len(dates)\n",
    "daily_pos_rate=['']*len(dates)\n",
    "for i in range(len(datestest)):\n",
    "  for j in range(var,len(dates)):\n",
    "    if (datestest[i]==dates[j]):\n",
    "      if (int(daily_tested[i])!=0):\n",
    "        daily_pos_rate[j]=(int(daily_confirmed[j])*100/int(daily_tested[i]))\n",
    "        pos_rate_cum[j]=(int(total_confirmed[j])*100/int(y_cumulative[i]))\n",
    "        test_per_million[j]=(int(y_cumulative[i])*1000000/int(population['Population'][36]))\n",
    "        daily_tested_final[j]=daily_tested[i]\n",
    "        tested_cum[j]=y_cumulative[i]\n",
    "      else:\n",
    "        daily_pos_rate[j]=('')\n",
    "        #test_per_million.append('')\n",
    "      var=j\n",
    "      break\n",
    "#print(len(y_cumulative))\n",
    "#daily_confirmed_7day_moving = []\n",
    "## India : date : []\n",
    "##        cumulative pos rate : [] x_cum/y_cum\n",
    "##        daily_pos_rate : []  (after taking moving avg) -> 7 observation moving avg\n",
    "## daily confirmed : [] (7 day moving average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "YbL5ikpZLHEu",
    "outputId": "4a08a12c-a83f-4871-cf7e-fa07ecee13fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    }
   ],
   "source": [
    "print(len(daily_confirmed_ma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nStuZRVIeYW9",
    "outputId": "75ef9f0a-c252-4cb4-d09a-3550ee6e6cac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "132"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(daily_pos_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fvcjz9x_PySN"
   },
   "outputs": [],
   "source": [
    "daily_pos_rate_ma=['']*len(dates)\n",
    "from statistics import mean\n",
    "count=0\n",
    "temp=['']*len(dates)\n",
    "\n",
    "i=0\n",
    "l=len(dates)\n",
    "#print(datestest)\n",
    "# for i in range(len(dates)):\n",
    "#print(daily_pos_rate)\n",
    "\n",
    "while i<l:\n",
    "  # print(i)\n",
    "  count+=1\n",
    "  for j in range(len(datestest)):\n",
    "    if (dates[i]==datestest[j]):\n",
    "      a=daily_pos_rate[i]\n",
    "      temp[i]=str(a)\n",
    "  \n",
    "  for k in range(7,len(temp)):\n",
    "    sum=0\n",
    "    counter=0\n",
    "    for m in range(0,7):\n",
    "      if (len(str(temp[k-m]))!=0):\n",
    "        sum+=float(temp[k-m])\n",
    "      else:\n",
    "        counter+=1\n",
    "    if ((7-counter)!=0):\n",
    "      daily_pos_rate_ma[k]=(sum/(7-counter))\n",
    "     \n",
    "  i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NEMGRp4MCPDO"
   },
   "outputs": [],
   "source": [
    "india_dates = dates\n",
    "india_total_cases=total_confirmed\n",
    "india_daily_confirmed = daily_confirmed\n",
    "india_daily_confirmed_ma = daily_confirmed_ma\n",
    "india_total_confirmed = total_confirmed\n",
    "india_daily_pos_rate_ma = daily_pos_rate_ma\n",
    "india_pos_rate_cum = pos_rate_cum\n",
    "india_daily_pos_rate = daily_pos_rate\n",
    "india_test_per_million=test_per_million\n",
    "india_daily_tested=daily_tested_final\n",
    "india_tested_cum = tested_cum\n",
    "# nationwide={\n",
    "#     'dates':dates,\n",
    "#     'daily_confirmed':daily_confirmed,\n",
    "#     'daily_confirmed_ma':daily_confirmed_ma,\n",
    "#     'daily_total':total_confirmed,\n",
    "#     'daily_positve_rate_ma':daily_pos_rate_ma\n",
    "# }\n",
    "# with open('nation.json', 'w') as outfile:\n",
    "#     json.dump(nationwide, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "o4iPB4lDDtsx",
    "outputId": "0206e86e-bba8-4734-8da9-288043554f0e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132\n"
     ]
    }
   ],
   "source": [
    "print(len(india_total_confirmed ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Pwh5O3yAWnYF"
   },
   "source": [
    "### State Level Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mqUi8q4iZUAt"
   },
   "outputs": [],
   "source": [
    "population=population.set_index('State')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 55
    },
    "colab_type": "code",
    "id": "oAcwapcpbw8l",
    "outputId": "ec8d091b-6354-4b71-a8c8-6fa2d444644f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maharashtra ['', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', '', 4.87617952770992, '', '', 3.783333333333333, 5.530605194560472, 4.93719860939778, 5.0245437382001255, 5.697450756007889, 5.9589739045678085, 5.730906803977831, 5.754517044434067, 5.523052887012598, 5.465896161446794, 5.894477082486224, 6.165774413882223, 6.35327566096423, 5.849972532708499, 6.750341350698456, 6.755390835579515, 7.3421683845933, 7.006695788861195, 7.121538716630742, 7.238630890418408, 7.306881660206052, 7.282236974451821, 7.615580633418275, 7.696833882093719, 7.705465214344257, 8.29383480775483, 8.542141230068337, 8.856357678892294, 8.965617003446779, 9.070103818740662, 8.969333640765505, 10.689585864768814, 10.527523348509115, 10.571667222075556, 10.779185136517494, 10.970195059346826, 11.11471840803621, 11.204933586337761, 11.702786816174935, 11.913467812092215, 12.075373534719626, 12.283344950784725, 12.50183885891674, 12.776701477651805, 12.983189809337771, 13.247095744821129, 13.478197447518534, 13.51982618142314, 13.543794726415252, 13.702438070254162, 13.86971455062954, 14.069783257804252, 14.323247463712887, 14.442102049572593, 14.50127061617363, 14.645808551931385, 14.845935702535487, 14.912204070935616, 15.001545935996441, 15.209007765925454, 15.282050219750248]\n"
     ]
    }
   ],
   "source": [
    "testing = {}\n",
    "states = np.unique([x['state'] for x in json.load(open('test.json',))['states_tested_data']])\n",
    "#df=pd.DataFrame()\n",
    "csv_dates=[]\n",
    "csv_states=[]\n",
    "csv_total_cases=[]\n",
    "csv_positivity_rate_cumulative=[]\n",
    "csv_daily_positive_cases=[]\n",
    "csv_daily_positivity_rate=[]\n",
    "csv_daily_positive_cases_ma=[]\n",
    "csv_daily_positivity_rate_ma=[]\n",
    "csv_test_per_million=[]\n",
    "csv_daily_tested=[]\n",
    "csv_cum_tested=[]\n",
    "for st in states:\n",
    "  state_dates = []\n",
    "  test_per_million=['']*len(dates)\n",
    "  pos_cum=['']*len(dates)\n",
    "  pos_rate_cum=['']*len(dates)\n",
    "  daily_pos=['']*len(dates)\n",
    "  daily_pos_ma=['']*len(dates)\n",
    "  daily_tested=['']*len(dates)\n",
    "  daily_pos_rate=['']*len(dates)\n",
    "  daily_pos_rate_ma=['']*len(dates)\n",
    "  tested_cum=['']*len(dates)\n",
    "  tested_daily=['']*len(dates)\n",
    "  state_date = [x['updatedon'] for x in filter(lambda v: v['state'] == st,json.load(open('test.json',))['states_tested_data'])]\n",
    "  #rates = [x['testpositivityrate'] for x in filter(lambda v: v['state'] == st,json.load(open('test.json',))['states_tested_data'])]\n",
    "  #print(state_date)\n",
    "  for i in (state_date):\n",
    "    state_dates.append(convert(i))\n",
    "  for i in range(len(dates)):\n",
    "    for j in range(len(state_dates)):\n",
    "      sum=0\n",
    "      count=0\n",
    "      sum1=0\n",
    "      count1=0\n",
    "      if (dates[i]==state_dates[j]):\n",
    "        pos_cum[i] = [x['positive'] for x in filter(lambda v: v['state'] == st,json.load(open('test.json',))['states_tested_data'])][j]\n",
    "        tested_cum[i] = [x['totaltested'] for x in filter(lambda v: v['state'] == st,json.load(open('test.json',))['states_tested_data'])][j]\n",
    "        if (j==0):\n",
    "          daily_pos[i]=pos_cum[j]\n",
    "          daily_tested[i]=tested_cum[j]\n",
    "        if(len(pos_cum[i])!=0 and len(pos_cum[i-1])!=0):\n",
    "          daily_pos[i]=int(pos_cum[i])-int(pos_cum[i-1]) \n",
    "          #print(daily_pos[i])\n",
    "        if(st=='Andaman and Nicobar Islands'):\n",
    "          daily_pos[i]=pos_cum[i]\n",
    "        if(len(tested_cum[i])!=0 and len(tested_cum[i-1])!=0):\n",
    "          daily_tested[i]=(int(tested_cum[i])-int(tested_cum[i-1]))\n",
    "          test_per_million[i]=int(tested_cum[i])*1000000/int(population[\"Population\"][st])\n",
    "          if (len(str(daily_pos[i]))!=0 and len(str(tested_cum[i]))!=0):\n",
    "            pos_rate_cum[i]=int(pos_cum[i])*100/int(tested_cum[i])\n",
    "          #if(st=='Maharashtra'):\n",
    "            #print(tested_cum[i],daily_tested[i])\n",
    "        if (j>6):\n",
    "          for k in range(0,7):\n",
    "            if (len(str(daily_pos[i-k]))!=0):\n",
    "              count+=1\n",
    "              sum+=daily_pos[i-k]\n",
    "          if (count!=0):\n",
    "            daily_pos_ma[i]=sum/count\n",
    "          if(len(str(daily_tested[i]))!=0 and daily_tested[i]!=0 and len(str(daily_pos[i]))!=0 ):\n",
    "            daily_pos_rate[i]=(int(daily_pos[i])*100/int(daily_tested[i]))\n",
    "        if (j>6):\n",
    "          for k in range(0,7):\n",
    "            if (len(str(daily_pos_rate[i-k]))!=0):\n",
    "              count1+=1\n",
    "              sum1+=daily_pos_rate[i-k]\n",
    "            if (count1!=0):\n",
    "             daily_pos_rate_ma[i]=sum1/count1\n",
    "  if(st==\"Maharashtra\"):\n",
    "    print(st,pos_rate_cum)\n",
    "  for i in range(len(dates)):\n",
    "    csv_dates.append(dates[i])\n",
    "    csv_total_cases.append(pos_cum[i])\n",
    "    csv_states.append(st)\n",
    "    csv_positivity_rate_cumulative.append(pos_rate_cum[i])\n",
    "    csv_daily_positive_cases.append(daily_pos[i])\n",
    "    csv_daily_positivity_rate.append(daily_pos_rate[i])\n",
    "    csv_daily_positive_cases_ma.append(daily_pos_ma[i])\n",
    "    csv_daily_positivity_rate_ma.append(daily_pos_rate_ma[i])\n",
    "    csv_test_per_million.append(test_per_million[i])\n",
    "    csv_daily_tested.append(daily_tested[i])\n",
    "    csv_cum_tested.append(tested_cum[i])\n",
    "  testing[st] = {\n",
    "                    'dates':dates,\n",
    "                    'cum_positive_cases':pos_cum,\n",
    "                    'cum_positivity_rate':pos_rate_cum,\n",
    "                    'daily_positive_cases':daily_pos,\n",
    "                    'daily_positivity_rate':daily_pos_rate,\n",
    "                    'daily_positive_cases_ma': daily_pos_ma,\n",
    "                    'daily_positivity_rate_ma':daily_pos_rate_ma , \n",
    "                    'test_per_million':test_per_million,\n",
    "                    'daily_tests': daily_tested,\n",
    "                    'cum_tests': tested_cum    \n",
    "                  }\n",
    "testing['India'] = {\n",
    "                    'dates': india_dates,\n",
    "                    'cum_positive_cases':india_total_cases,\n",
    "                    'cum_positivity_rate': india_pos_rate_cum,\n",
    "                    'daily_positive_cases': india_daily_confirmed,\n",
    "                    'daily_positivity_rate': india_daily_pos_rate,\n",
    "                    'daily_positive_cases_ma': india_daily_confirmed_ma,\n",
    "                    'daily_positivity_rate_ma': india_daily_pos_rate_ma,\n",
    "                    'test_per_million':india_test_per_million,  \n",
    "                    'daily_tests':india_daily_tested,\n",
    "                    'cum_tests':india_tested_cum   \n",
    "                  }\n",
    "for i in range (len(dates)):\n",
    "    csv_dates.append(dates[i])\n",
    "    csv_states.append('India')\n",
    "    csv_total_cases.append(india_total_cases[i])\n",
    "    csv_positivity_rate_cumulative.append(india_pos_rate_cum[i])\n",
    "    csv_daily_positive_cases.append(india_daily_confirmed[i])\n",
    "    csv_daily_positivity_rate.append(india_daily_pos_rate[i])\n",
    "    csv_daily_positive_cases_ma.append(india_daily_confirmed_ma[i])\n",
    "    csv_daily_positivity_rate_ma.append(india_daily_pos_rate_ma[i])\n",
    "    csv_test_per_million.append(india_test_per_million[i])\n",
    "    csv_daily_tested.append(india_daily_tested[i])\n",
    "    csv_cum_tested.append(india_tested_cum[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-Ll534S9Wb7"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "testing['datetime']=str(datetime.now())\n",
    "with open('positivity_Rate.json', 'w') as outfile:\n",
    "    json.dump(testing, outfile,indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQ0xG1mwoLjZ"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame()\n",
    "df['dates']=csv_dates\n",
    "df['state']=csv_states\n",
    "df['cum_positive_cases']=csv_total_cases\n",
    "df['cum_positivity_rate']=csv_positivity_rate_cumulative\n",
    "df['daily_positive_cases']=csv_daily_positive_cases\n",
    "df['daily_positivity_rate']=csv_daily_positivity_rate\n",
    "df['daily_positive_cases_ma']=csv_daily_positive_cases_ma\n",
    "df['daily_positivity_rate_ma']=    csv_daily_positivity_rate_ma\n",
    "df['test_per_million']=csv_test_per_million\n",
    "df['daily_tested']=csv_daily_tested\n",
    "df['cum_tested']=csv_cum_tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CPhEpjzIAyTt"
   },
   "outputs": [],
   "source": [
    "df.to_csv('positivity_Rate.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ne5lacQ_fLj8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CFRCalculation_positivityrate.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
