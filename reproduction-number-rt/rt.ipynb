{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "name": "rt.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS04bS_xzt2l",
        "colab_type": "code",
        "outputId": "1a2765b5-423d-4f41-c4a6-112e63bf88e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        }
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=3d832c6639a16276f1f26b3073057b8710368c2d730bd06fc4431977da124f52\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg4B7WwDzp_9",
        "colab_type": "code",
        "outputId": "c92faedb-0f6c-4e41-a0a6-23bd90043317",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from subprocess import call\n",
        "from scipy.stats.distributions import gamma\n",
        "import json \n",
        "import wget\n",
        "import os\n",
        "import os.path\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive/minimal')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7FrMFo_0gK0",
        "colab_type": "code",
        "outputId": "a0346394-d2f0-4f9d-b3fd-fb14b1242070",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "if os.path.exists(os.getcwd()+\"\\\\national.json\"):\n",
        "    os.remove(os.getcwd()+\"\\\\national.json\")\n",
        "wget.download('https://api.covid19india.org/data.json', os.getcwd()+\"//national.json\")\n",
        "\n",
        "if os.path.exists(os.getcwd()+\"\\\\states.json\"):\n",
        "    os.remove(os.getcwd()+\"\\\\states.json\")\n",
        "wget.download('https://api.covid19india.org/states_daily.json', os.getcwd()+\"//states.json\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/minimal//states (1).json'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onP6Jq5RzqAH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pooled_SD(sds,means):\n",
        "    return np.sqrt((np.sum(sds**2,axis=0)+np.sum(means-np.mean(means,axis=0)))/sds.shape[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "colNKV4kzqAO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_data = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNOfWkFFBreC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fn(mon):\n",
        "  if(mon == \"01\"):\n",
        "    return \" January\"\n",
        "  if(mon == \"02\"):\n",
        "    return \" February\"\n",
        "  if(mon == \"03\"):\n",
        "    return \" March\"\n",
        "  if(mon == \"04\"):\n",
        "    return \" April\"\n",
        "  if(mon == \"05\"):\n",
        "    return \" May\"\n",
        "  if(mon == \"06\"):\n",
        "    return \" June\"\n",
        "  if(mon == \"07\"):\n",
        "    return \" July\"\n",
        "  if(mon == \"08\"):\n",
        "    return \" August\"\n",
        "  if(mon == \"09\"):\n",
        "    return \" September\"\n",
        "  if(mon == \"10\"):\n",
        "    return \" October\"\n",
        "  if(mon == \"11\"):\n",
        "    return \" November\"\n",
        "  if(mon == \"12\"):\n",
        "    return \" December\"\n",
        "def convert(dat): \n",
        "    return  str(dat[3:5]) + fn(str(dat[:2]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w93pDNZ4zqAV",
        "colab_type": "text"
      },
      "source": [
        "### Calculation for Rt (India - No Import Adjustment)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWN18py3zqAW",
        "colab_type": "code",
        "outputId": "9b9b19b0-e489-4119-d5e7-048047aac3e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "dates = np.array([pd.to_datetime(i['date']+\"2020\") for i in json.load(open('national.json',))['cases_time_series']])\n",
        "confirmed = np.array([int(i['dailyconfirmed'])for i in json.load(open('national.json',))['cases_time_series']])\n",
        "\n",
        "confirmed = confirmed[dates>=pd.to_datetime(\"03/04/20\")]\n",
        "dates = dates[dates>=pd.to_datetime(\"03/04/20\")]\n",
        "\n",
        "real_data = confirmed\n",
        "\n",
        "rt = []\n",
        "dats = []\n",
        "for n in range(100):\n",
        "    print(\"Iteration: \",n+1,end='\\r')\n",
        "    dataset = np.copy(real_data)\n",
        "    G = gamma(3.325+0.616*np.random.normal(),0.979+0.195*np.random.normal())\n",
        "    for i in range(len(dataset)):\n",
        "        send_back = np.clip(np.round(G.rvs(np.max([0,int(dataset[i])]))),0,10)\n",
        "        send_back = send_back[i-send_back>=0]\n",
        "        dataset[i] = 0\n",
        "        for j in np.unique(np.int32(send_back)):\n",
        "            dataset[i-j] += np.sum(send_back==j)\n",
        "    dataset[::-1] = dataset[::-1]+np.random.negative_binomial(n=dataset[::-1]+1,p=G.cdf(np.arange(len(dataset))),size=len(dataset)) \n",
        "    df = pd.DataFrame()\n",
        "    df['active'] = dataset[:-3]\n",
        "    df['date'] = dates[:-3]\n",
        "    df.to_csv('dataset.csv',index=False)\n",
        "    call(['RScript.exe','scripts/Rt_analysis.R'])\n",
        "    rt.append(pd.read_csv('rtoutput.csv'))\n",
        "    dats.append(dataset[:-3])\n",
        "\n",
        "means = np.array([x[\"Mean(R)\"].values for x in rt])\n",
        "sds = np.array([x[\"Std(R)\"].values for x in rt])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FWgMISj0U2pN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stindex = 2+5-1\n",
        "unchanged=list(pd.Series(dates)[stindex:stindex+means.shape[1]].dt.strftime('%m-%d-%Y'))\n",
        "changed=[]\n",
        "for i in unchanged:\n",
        "  changed.append(convert(i))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UsTogwOJzqAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df=pd.DataFrame()\n",
        "csv_dates=[]\n",
        "csv_rt_point=[]\n",
        "csv_rt_sd=[]\n",
        "csv_rt_l95=[]\n",
        "csv_rt_u95=[]\n",
        "csv_rt_l50=[]\n",
        "csv_rt_u50=[]\n",
        "csv_cases_mean=[]\n",
        "csv_cases_sd=[]\n",
        "csv_cases_dates=[]\n",
        "#dates=[]\n",
        "india = {\n",
        "        'dates':changed,\n",
        "        'rt_point':list(means.mean(axis=0)),\n",
        "        'rt_sd':list(pooled_SD(sds,means)),\n",
        "        'rt_l95':list(means.mean(axis=0)-1.95996*pooled_SD(sds,means)),\n",
        "        'rt_u95':list(means.mean(axis=0)+1.95996*pooled_SD(sds,means)),\n",
        "        'rt_l50':list(means.mean(axis=0)-0.67449*pooled_SD(sds,means)),\n",
        "        'rt_u50':list(means.mean(axis=0)+0.67449*pooled_SD(sds,means)),\n",
        "        'cases_mean':list(np.mean(dats,axis=0)),\n",
        "        'cases_sd':list(np.std(dats,axis=0)),\n",
        "        'cases_dates':list(pd.Series(dates)[:-3].dt.strftime('%m-%d-%Y'))\n",
        "        }\n",
        "for i in range(len(changed)):\n",
        "  csv_dates.append(changed[i])\n",
        "  csv_rt_point.append(list(means.mean(axis=0))[i])\n",
        "  csv_rt_sd.append(list(pooled_SD(sds,means))[i])\n",
        "  csv_rt_l95.append(list(means.mean(axis=0)-1.95996*pooled_SD(sds,means))[i])\n",
        "  csv_rt_u95.append(list(means.mean(axis=0)+1.95996*pooled_SD(sds,means))[i])\n",
        "  csv_rt_l50.append(list(means.mean(axis=0)-0.67449*pooled_SD(sds,means))[i])\n",
        "  csv_rt_u50.append(list(means.mean(axis=0)+0.67449*pooled_SD(sds,means))[i])\n",
        "  csv_cases_mean.append(list(np.mean(dats,axis=0))[i])\n",
        "  csv_cases_sd.append(list(np.std(dats,axis=0))[i])\n",
        "  csv_cases_dates.append(list(pd.Series(dates)[:-3].dt.strftime('%m-%d-%Y'))[i])\n",
        "df['dates']=csv_dates\n",
        "df['state']=['India']*len(csv_dates)\n",
        "df['rt_point']=csv_rt_point\n",
        "df['rt_sd']=csv_rt_sd\n",
        "df['rt_l95']=csv_rt_l95\n",
        "df['rt_u95']=csv_rt_u95\n",
        "df['rt_l50']= csv_rt_l50\n",
        "df['rt_u50']=csv_rt_u50\n",
        "df['cases_mean']=csv_cases_mean\n",
        "df['cases_sd']=csv_cases_sd\n",
        "df['cases_dates']=csv_cases_dates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMAg9Yo5zqAl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json_data['IN'] = india"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GR9UQk46zqAr",
        "colab_type": "text"
      },
      "source": [
        "### State Level Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9640HhV4zqAs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "states = list(filter(lambda v:len(v)<3,list(json.load(open('states.json',))['states_daily'][0].keys())))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXFb8gevzqAy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dates = np.array([pd.to_datetime(i['date']) for i in filter(lambda v: v['status'] == 'Confirmed',json.load(open('states.json',))['states_daily'])])\n",
        "data = pd.DataFrame()\n",
        "for st in states:\n",
        "    data[st] = np.array([i[st] for i in filter(lambda v: v['status'] == 'Confirmed',json.load(open('states.json',))['states_daily'])])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yoileJ5bzqA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data.replace(r'^\\s*$', np.NaN, regex=True).fillna(0)\n",
        "data = data.astype(np.int32)\n",
        "data['date'] = dates"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "HuUH522NzqA8",
        "colab_type": "code",
        "outputId": "7e65bb20-a1ab-4215-f3a6-9fb2a109ad20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "state_id = {\n",
        "  \"mh\":\"Maharashtra\",\n",
        "  \"tn\":\"Tamil Nadu\",\n",
        "  \"dl\":\"Delhi\",\n",
        "  \"gj\":\"Gujarat\",\n",
        "  \"rj\":\"Rajasthan\",\n",
        "  \"up\":\"Uttar Pradesh\",\n",
        "  \"mp\":\"Madhya Pradesh\",\n",
        "  \"wb\":\"West Bengal\",\n",
        "  \"ka\":\"Karnataka\",\n",
        "  \"br\":\"Bihar\",\n",
        "  \"ap\":\"Andhra Pradesh\",\n",
        "  \"hr\":\"Haryana\",\n",
        "  \"tg\":\"Telangana\",\n",
        "  \"jk\":\"Jammu and Kashmir\",\n",
        "  \"or\":\"Odisha\",\n",
        "  \"pb\":\"Punjab\",\n",
        "  \"as\":\"Assam\",\n",
        "  \"kl\":\"Kerala\",\n",
        "  \"ut\":\"Uttarakhand\",\n",
        "  \"jh\":\"Jharkand\",\n",
        "  \"ct\":\"Chhattisgarh\",\n",
        "  \"tr\":\"Tripura\",\n",
        "  \"hp\":\"Himachal Pradesh\",\n",
        "  \"ch\":\"Chandigarh\",\n",
        "  \"ga\":\"Goa\",\n",
        "  \"mn\":\"Manipur\",\n",
        "  \"nl\":\"Nagaland\",\n",
        "  \"py\":\"Puducherry\",\n",
        "  \"la\":\"Ladakh\",\n",
        "  \"ar\":\"Arunachal Pradesh\",\n",
        "  \"an\":\"Andaman and Nicobar Islands\",\n",
        "  \"ml\":\"Meghalaya\",\n",
        "  \"mz\":\"Mizoram\",\n",
        "  \"dn\":\"Dadra and Nagar Haveli and Daman and Diu\",\n",
        "  \"sk\":\"Sikkim\",\n",
        "}\n",
        "for state in state_id.keys():\n",
        "    csv_dates=[]\n",
        "    csv_rt_point=[]\n",
        "    csv_rt_sd=[]\n",
        "    csv_rt_l95=[]\n",
        "    csv_rt_u95=[]\n",
        "    csv_rt_l50=[]\n",
        "    csv_rt_u50=[]\n",
        "    csv_cases_mean=[]\n",
        "    csv_cases_sd=[]\n",
        "    csv_cases_dates=[]\n",
        "    print(\"\\n\",state)\n",
        "    boots = 100\n",
        "    real_data = data[state].values\n",
        "    active = pd.DataFrame()\n",
        "    active['active'] = real_data\n",
        "    active.to_csv('dataset.csv',index=False)\n",
        "    rt = []\n",
        "    dats = []\n",
        "    for n in range(boots):\n",
        "        print(\"Iteration: \",n+1,end='\\r')\n",
        "        G = gamma(3.325+0.616*np.random.normal(),0.979+0.195*np.random.normal())\n",
        "        dataset = np.copy(real_data)\n",
        "        for i in range(len(dataset)):\n",
        "            send_back = np.clip(np.round(G.rvs(np.max([0,int(dataset[i])]))),0,10)\n",
        "            send_back = send_back[i-send_back>=0]\n",
        "            dataset[i] = 0\n",
        "            for j in np.unique(np.int32(send_back)):\n",
        "                dataset[i-j] += np.sum(send_back==j)\n",
        "        dataset[::-1] = dataset[::-1]+np.random.negative_binomial(n=dataset[::-1]+1,p=G.cdf(np.arange(len(dataset))),size=len(dataset)) \n",
        "        active = pd.DataFrame()\n",
        "        active['active'] = dataset[:-3]\n",
        "        active['date'] = dates[:-3]\n",
        "        dats.append(dataset[:-3])\n",
        "        active.to_csv('dataset.csv',index=False)\n",
        "        call(['RScript.exe','scripts/Rt_analysis.R'])\n",
        "        rt.append(pd.read_csv('rtoutput.csv'))\n",
        "\n",
        "    means = np.array([x[\"Mean(R)\"].values for x in rt])\n",
        "    sds = np.array([x[\"Std(R)\"].values for x in rt])\n",
        "    dat_means = np.mean(dats,axis=0)\n",
        "    dat_sds = np.std(dats,axis=0)\n",
        "    unchanged=list(pd.Series(dates)[stindex:stindex+means.shape[1]].dt.strftime('%m-%d-%Y'))\n",
        "    changed=[]\n",
        "    unchanged=list(pd.Series(dates)[stindex:stindex+means.shape[1]].dt.strftime('%m-%d-%Y'))\n",
        "    for i in unchanged:\n",
        "      changed.append(convert(i))\n",
        "    stindex = 2+5-1\n",
        "    temp = {\n",
        "            'dates':changed,\n",
        "            'rt_point':list(means.mean(axis=0)),\n",
        "            'rt_sd':list(pooled_SD(sds,means)),\n",
        "            'rt_l95':list(means.mean(axis=0)-1.95996*pooled_SD(sds,means)),\n",
        "            'rt_u95':list(means.mean(axis=0)+1.95996*pooled_SD(sds,means)),\n",
        "            'rt_l50':list(means.mean(axis=0)-0.67449*pooled_SD(sds,means)),\n",
        "            'rt_u50':list(means.mean(axis=0)+0.67449*pooled_SD(sds,means)),\n",
        "            'cases_mean':list(np.mean(dats,axis=0)),\n",
        "            'cases_sd':list(np.std(dats,axis=0)),\n",
        "            'cases_dates':list(pd.Series(dates)[:-3].dt.strftime('%m-%d-%Y'))\n",
        "            }\n",
        "    state_df=pd.DataFrame()\n",
        "    for i in range(len(changed)):\n",
        "      csv_dates.append(changed[i])\n",
        "      csv_rt_point.append(list(means.mean(axis=0))[i])\n",
        "      csv_rt_sd.append(list(pooled_SD(sds,means))[i])\n",
        "      csv_rt_l95.append(list(means.mean(axis=0)-1.95996*pooled_SD(sds,means))[i])\n",
        "      csv_rt_u95.append(list(means.mean(axis=0)+1.95996*pooled_SD(sds,means))[i])\n",
        "      csv_rt_l50.append(list(means.mean(axis=0)-0.67449*pooled_SD(sds,means))[i])\n",
        "      csv_rt_u50.append(list(means.mean(axis=0)+0.67449*pooled_SD(sds,means))[i])\n",
        "      csv_cases_mean.append(list(np.mean(dats,axis=0))[i])\n",
        "      csv_cases_sd.append(list(np.std(dats,axis=0))[i])\n",
        "      csv_cases_dates.append(list(pd.Series(dates)[:-3].dt.strftime('%m-%d-%Y'))[i])\n",
        "    state_df['dates']=csv_dates\n",
        "    state_df['state']=[state]*len(csv_dates)\n",
        "    state_df['rt_point']=csv_rt_point\n",
        "    state_df['rt_sd']=csv_rt_sd\n",
        "    state_df['rt_l95']=csv_rt_l95\n",
        "    state_df['rt_u95']=csv_rt_u95\n",
        "    state_df['rt_l50']= csv_rt_l50\n",
        "    state_df['rt_u50']=csv_rt_u50\n",
        "    state_df['cases_mean']=csv_cases_mean\n",
        "    state_df['cases_sd']=csv_cases_sd\n",
        "    state_df['cases_dates']=csv_cases_dates\n",
        "    df=pd.concat([df,state_df])\n",
        "    json_data[state] = temp\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " kl\n",
            "\n",
            " mh\n",
            "Iteration:  100\n",
            " gj\n",
            "Iteration:  100\n",
            " dl\n",
            "\n",
            " rj\n",
            "Iteration:  100\n",
            " tn\n",
            "Iteration:  100\n",
            " mp\n",
            "\n",
            " up\n",
            "\n",
            " tg\n",
            "\n",
            " ap\n",
            "Iteration:  100\n",
            " ka\n",
            "Iteration:  100\n",
            " wb\n",
            "Iteration:  100\n",
            " jk\n",
            "\n",
            " hr\n",
            "\n",
            " pb\n",
            "Iteration:  100\n",
            " br\n",
            "Iteration:  100\n",
            " or\n",
            "Iteration:  100\n",
            " jh\n",
            "Iteration:  100\n",
            " ut\n",
            "Iteration:  100\n",
            " hp\n",
            "\n",
            " ct\n",
            "\n",
            " as\n",
            "\n",
            " ch\n",
            "\n",
            " la\n",
            "Iteration:  100\n",
            " an\n",
            "Iteration:  100\n",
            " ml\n",
            "Iteration:  100\n",
            " ga\n",
            "\n",
            " py\n",
            "\n",
            " mn\n",
            "Iteration:  100\n",
            " tr\n",
            "\n",
            " ar\n",
            "Iteration:  100\n",
            " mz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq5318Ms3FZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv('rt.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbOg8nEFzqBC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('rt.json', 'w') as outfile:\n",
        "    json.dump(json_data, outfile)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_7vvG1XOPCo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}